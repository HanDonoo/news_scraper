import pandas as pd
from scraper import fetch_article_with_selenium
from translator import translate_via_api

def main():
    urls = [
        "https://m.huanqiu.com/article/4OwsQhxR5g0",
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šé“¾æ¥
    ]

    articles = []

    for url in urls:
        print(f"\n====== æŠ“å–æ–‡ç«  ======\n{url}")
        article = fetch_article_with_selenium(url, headless=True)

        # æ•´ç†åŸæ–‡å†…å®¹
        full_content = "\n".join(article["content_blocks"])

        # ç¿»è¯‘è°ƒç”¨
        translation = translate_via_api(article["title"], full_content)

        # ä½¿ç”¨è¿”å›çš„æ­£ç¡®é”®å 'title_translated' å’Œ 'content_translated'
        title_en = translation.get("title_translated", "")
        content_en = translation.get("content_translated", "")

        # é€šè¿‡ append å°†ç»“æœæ·»åŠ åˆ° articles åˆ—è¡¨
        articles.append({
            "title_zh": article["title"],
            "title_en": title_en,  # ä½¿ç”¨ç¿»è¯‘åçš„æ ‡é¢˜
            "content_zh": full_content,
            "content_en": content_en,  # ä½¿ç”¨ç¿»è¯‘åçš„å†…å®¹
            "cover": article["cover"],
            "url": url
        })

    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(articles)
    print("\nğŸ“Š æŠ“å–ä¸ç¿»è¯‘ç»“æœé¢„è§ˆï¼š")
    print(df.head())

    df.to_csv("articles_translated.csv", index=False, encoding="utf-8-sig")
    print("\nğŸ“ CSV æ–‡ä»¶ä¿å­˜å®Œæˆï¼šarticles_translated.csv")

if __name__ == "__main__":
    main()

import os
import time
import html
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager


def fetch_article_with_selenium(url, headless=True):
    """ä½¿ç”¨ Selenium æ¨¡æ‹Ÿæµè§ˆå™¨åŠ è½½å¹¶æŠ“å–ç¯çƒç½‘æ–‡ç« å†…å®¹"""
    os.environ["PYDEVD_USE_CYTHON"] = "NO"  # è§£å†³ PyCharm è°ƒè¯•é—®é¢˜

    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1280,1024")

    print("ğŸš€ å¯åŠ¨ Chrome æµè§ˆå™¨...")
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=chrome_options
    )

    print(f"ğŸŒ æ­£åœ¨è®¿é—® {url}")
    driver.get(url)
    time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆå¯è°ƒæ•´ï¼‰

    html_content = driver.page_source
    driver.quit()
    print("âœ… é¡µé¢åŠ è½½å®Œæˆï¼Œå¼€å§‹è§£æå†…å®¹...")

    return parse_article_html(html_content)

def parse_article_html(html_content):
    """è§£æ Selenium è·å–çš„ HTMLï¼Œæå–æ ‡é¢˜ã€æ­£æ–‡ï¼ˆä¿ç•™å›¾ç‰‡ä½ç½®ï¼‰ã€å°é¢"""
    soup = BeautifulSoup(html_content, "html.parser")

    # === æ ‡é¢˜ ===
    title_tag = soup.find("textarea", class_="article-title")
    title = title_tag.get_text(strip=True) if title_tag else "No Title Found"

    # === æ­£æ–‡ ===
    content_textarea = soup.find("textarea", class_="article-content")
    content_blocks = []  # é¡ºåºä¿å­˜æ–‡æœ¬ä¸å›¾ç‰‡
    images = []
    seen_images = set()  # é˜²æ­¢é‡å¤æ·»åŠ 

    if content_textarea:
        raw_html = html.unescape(content_textarea.get_text(strip=True))
        content_soup = BeautifulSoup(raw_html, "html.parser")

        # éå†æ­£æ–‡ç»“æ„ï¼ˆä¸»è¦çœ‹ p å’Œ iï¼‰
        for element in content_soup.find_all(["p", "i"], recursive=True):
            # --- æ®µè½æ–‡å­— ---
            text = element.get_text(strip=True)
            if text:
                content_blocks.append(text)

            # --- æŸ¥æ‰¾å›¾ç‰‡ ---
            img = element.find("img")
            if img and img.get("src"):
                src = normalize_img_url(img["src"])
                if src not in seen_images:  # âœ… é¿å…é‡å¤
                    seen_images.add(src)
                    content_blocks.append(f"[IMAGE:{src}]")
                    images.append(src)

    # === å°é¢ ===
    cover_tag = soup.find("textarea", class_="article-cover")
    cover = cover_tag.get_text(strip=True) if cover_tag else ""
    cover = normalize_img_url(cover)

    return {
        "title": title,
        "content_blocks": content_blocks,  # å«å›¾ç‰‡ä½ç½®æ ‡è®°
        "images": images,
        "cover": cover
    }

def normalize_img_url(src):
    """ç»Ÿä¸€è¡¥å…¨ https:// å¼€å¤´çš„å›¾ç‰‡é“¾æ¥"""
    if src and src.startswith("//"):
        return "https:" + src
    return src
